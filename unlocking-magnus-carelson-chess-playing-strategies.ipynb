{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":83735,"databundleVersionId":9881586,"sourceType":"competition"},{"sourceId":10070193,"sourceType":"datasetVersion","datasetId":6206788}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/datascientistsalman/unlocking-magnus-carelson-chess-playing-strategies?scriptVersionId=210686278\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Created by:** Salman Ahmed  \n**LinkedIn:** [Salman Ahmed ](https://www.linkedin.com/in/salmanahmed84/)  \n**Portfolio:** [Salman's Portfolio](https://github.com/salman-datascientist)","metadata":{"execution":{"iopub.status.busy":"2024-12-01T18:35:21.893362Z","iopub.execute_input":"2024-12-01T18:35:21.893771Z","iopub.status.idle":"2024-12-01T18:35:21.900702Z","shell.execute_reply.started":"2024-12-01T18:35:21.893735Z","shell.execute_reply":"2024-12-01T18:35:21.899313Z"}}},{"cell_type":"markdown","source":"**Gemini 1.5 with Long-Context Windows for Analyzing Hours-Long Chess Game Videos**\n\n***Extended Context Length:***\nVast Input Capacity: Gemini 1.5 Pro excels at processing hours-long chess game videos, managing inputs of up to 10 million tokens. This allows for seamless analysis of entire tournaments without segmenting the data into smaller chunks​.\nImproved Contextual Understanding: The extended context length enables the model to connect strategic decisions across games, identify long-term patterns, and correlate player behavior over time.\n\n***High Recall:***\nAccurate Information Retrieval: When analyzing hours of video, Gemini 1.5 Pro can precisely locate specific moves, strategies, or key moments, such as a player executing a checkmate or pivotal errors in gameplay. This high recall ensures no critical detail is missed​.\nSuperior Performance: Compared to other models, Gemini 1.5 Pro demonstrates unmatched accuracy in retrieving and reasoning over long video sequences, even outperforming specialized models like GPT-4V for video QA.\nMultimodal Capabilities:\n\n***Unified Understanding:***\nGemini 1.5 Pro integrates video, audio commentary, and text-based annotations in chess games to create a comprehensive analysis of gameplay strategies and decisions​(gemini_v1_5_report).\nEnhanced Contextual Awareness: By combining visual inputs (e.g., board state), audio (e.g., player commentary), and text (e.g., move notations), the model delivers richer insights into player strategies and decision-making processes.\nEfficiency and Scalability:\n\n***Optimized Processing:*** \nDesigned to handle extensive data, Gemini 1.5 Pro efficiently processes multiple hours of chess gameplay videos, ensuring that even tournaments spanning several days can be analyzed in one session.\nScalability: Its ability to analyze entire archives of chess games, such as championship series, makes it ideal for researchers, commentators, or AI systems studying gameplay evolution and strategy trends​.\nReduced Reliance on External Tools:\n\n***Self-Sufficiency:***\nUnlike systems that rely on external video processing or annotation tools, Gemini 1.5 Pro can directly analyze video content, extracting timestamps, moves, and strategic insights without additional preprocessing​.\n\n***Simplified Workflow:***\nThis all-in-one capability simplifies the workflow, enabling faster and more efficient analysis of chess games without requiring integration with separate retrieval or indexing systems​.","metadata":{}},{"cell_type":"markdown","source":"Install the SDK","metadata":{}},{"cell_type":"code","source":"%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<center>\n  <h2 style=\"color: blue;\">YouTube Video: <a href=\"https://www.youtube.com/watch?v=RkBgf06G89E\" target=\"_blank\" style=\"color: blue;\">Magnus Carlsen goes 94% BERSERK in Blitz Titled Arena</a></h2>\n</center>","metadata":{"execution":{"iopub.status.busy":"2024-12-01T18:36:13.844311Z","iopub.execute_input":"2024-12-01T18:36:13.844735Z","iopub.status.idle":"2024-12-01T18:36:13.852419Z","shell.execute_reply.started":"2024-12-01T18:36:13.844698Z","shell.execute_reply":"2024-12-01T18:36:13.850699Z"}}},{"cell_type":"code","source":"from IPython.display import HTML\n\n# Display a centered YouTube video\nvideo_id = \"RkBgf06G89E\"\nHTML(f\"\"\"\n<div style=\"display: flex; justify-content: center;\">\n    <iframe width=\"1024\" height=\"576\" src=\"https://www.youtube.com/embed/{video_id}\" frameborder=\"0\" allowfullscreen></iframe>\n</div>\n\"\"\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T19:26:35.962568Z","iopub.execute_input":"2024-12-01T19:26:35.962971Z","iopub.status.idle":"2024-12-01T19:26:36.398045Z","shell.execute_reply.started":"2024-12-01T19:26:35.962934Z","shell.execute_reply":"2024-12-01T19:26:36.396516Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/gemini-long-context/submission_instructions.txt\n/kaggle/input/magnus-chess-blitz/magnus_chess_blitz.mp4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport datetime\nimport google.generativeai as genai\nfrom google.generativeai import caching\nfrom IPython.display import HTML, Markdown, display, Video","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T19:35:35.202627Z","iopub.execute_input":"2024-12-01T19:35:35.203085Z","iopub.status.idle":"2024-12-01T19:35:35.208745Z","shell.execute_reply.started":"2024-12-01T19:35:35.203048Z","shell.execute_reply":"2024-12-01T19:35:35.207491Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Get GEMINI_API_KEY stored in User Secrets.","metadata":{}},{"cell_type":"code","source":"# Get the API key from here: https://ai.google.dev/tutorials/setup\n# Create a new secret called \"GEMINI_API_KEY\" via Add-ons -> Secrets in the top menu, and attach it to this notebook.\n\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T19:26:38.819358Z","iopub.execute_input":"2024-12-01T19:26:38.820438Z","iopub.status.idle":"2024-12-01T19:26:39.031041Z","shell.execute_reply.started":"2024-12-01T19:26:38.820398Z","shell.execute_reply":"2024-12-01T19:26:39.029607Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"\n**Choice of Gemini Model:**\n\ngemini-1.5-flash, alias that points to gemini-1.5-flash-002\nBest for:\r\nImage understandin, \r\nVideo understandi, g\r\nAudio understanding\r\nUse case:\r\nProcess 3,000 images at a, time\r\nLook through 1 hour long , ideos\r\nListen to hours o\nf audio\n!Testing ! - Run your first prompt\r\nIn this step, you will test that your API key is set up correctly by making a request. The gemini-1.5-flash model has been selected here.","metadata":{}},{"cell_type":"code","source":"# found 'gemini-1.5-flash-001' response to be vastly different and more useful, but still went with latest version of gemini flash\n#flash = genai.GenerativeModel('gemini-1.5-flash-001')\nflash = genai.GenerativeModel('gemini-1.5-flash-002')\nresponse = flash.generate_content(\"Explain AI to me like I'm a kid.\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T19:51:08.532437Z","iopub.execute_input":"2024-12-01T19:51:08.532818Z","iopub.status.idle":"2024-12-01T19:51:10.134908Z","shell.execute_reply.started":"2024-12-01T19:51:08.532786Z","shell.execute_reply":"2024-12-01T19:51:10.133697Z"}},"outputs":[{"name":"stdout","text":"Imagine you have a super smart friend who's really good at learning. This friend is called AI, short for Artificial Intelligence.\n\nAI is like a computer that can think and learn like a human. It can learn from all the information you give it, like books, pictures, or even your own words!\n\nThink about how you learn to play a game. First, you see how it's done, then you practice, and you get better over time. AI works the same way! It looks at lots of examples and then uses what it learned to solve problems or do tasks.\n\nHere are some things AI can do:\n\n* **Play games:** AI can play games like chess or video games better than humans sometimes!\n* **Help you find things:** AI helps you find what you're looking for online, like when you search for a video on YouTube.\n* **Translate languages:** AI can help you understand what people are saying in other languages.\n* **Drive cars:** AI can help drive cars safely and without human drivers.\n\nIt's like having a super smart friend that can help you with all sorts of things. And it's getting smarter all the time! \n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"***When to use context caching***\n\r\nContext caching is particularly well suited to scenarios where a substantial initial context is referenced repeatedly by shorter requests. Consider using context caching for use cases such as:\r\n* Chatbots with extensive system instructions\n* Repetitive analysis of lengthy video files\n* Recurring queries against large document sets\n* Frequent code repository analysis or bug fixingtput tokens.","metadata":{}},{"cell_type":"markdown","source":"***How caching reduces costs***\n\nContext caching is a paid feature designed to reduce overall operational costs. Billing is based on the following factors:\n\n1. **Cache token count**: The number of input tokens cached, billed at a reduced rate when included in subsequent prompts.\n2. **Storage duration**: The amount of time cached tokens are stored (TTL), billed based on the TTL duration of cached token count. There are no minimum or maximum bounds on the TTL.\n3. **Other factors**: Other charges apply, such as for non-cached input tokens and output tokens.\n","metadata":{}},{"cell_type":"code","source":"magnus_video1 = '/kaggle/input/magnus-chess-blitz/magnus_chess_blitz.mp4'\nVideo(magnus_video1, embed=True, width=640, height=480)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T20:13:24.825445Z","iopub.execute_input":"2024-12-01T20:13:24.825935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Upload the video using the Files API\nvideo_file = genai.upload_file(path=magnus_video1)\n\n# Wait for the file to finish processing\nwhile video_file.state.name == 'PROCESSING':\n  print('Waiting for video to be processed.')\n  time.sleep(2)\n  video_file = genai.get_file(video_file.name)\n\nprint(f'Video processing complete: {video_file.uri}')\n\n# Create a cache with a 5 minute TTL\ncache = caching.CachedContent.create(\n    model='models/gemini-1.5-flash-002',\n    display_name='magnus chess blitz of 51 games', # used to identify the cache\n    system_instruction=(\n        'You are an expert video analyzer, and your job is to answer '\n        'the user\\'s query based on the video file you have access to.'\n    ),\n    contents=[video_file],\n    ttl=datetime.timedelta(minutes=5),\n)\n\n# Construct a GenerativeModel which uses the created cache.\nmodel = genai.GenerativeModel.from_cached_content(cached_content=cache)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport glob\n\n# Directory containing your JSON files\ndata_folder = \"/kaggle/input/magnus-chess-blitz\"\n# List all JSON files in the directory\njson_files = glob.glob(os.path.join(data_folder, \"*.json\"))\n\n\ndata_list = []\nfor json_file in json_files:\n    # Read the content of the JSON file\n    with open(json_file, 'r') as file:\n        data = json.load(file)\n    \n    # Convert JSON data to a string\n    data_str = json.dumps(data)\n    data_list.append(data_str)\n    print(json_file, flash.count_tokens(data_str))\n\nprint('Token size of combined video files', flash.count_tokens(data_list))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T19:45:08.315261Z","iopub.execute_input":"2024-12-01T19:45:08.315756Z","iopub.status.idle":"2024-12-01T19:45:08.347661Z","shell.execute_reply.started":"2024-12-01T19:45:08.315717Z","shell.execute_reply":"2024-12-01T19:45:08.346083Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     data_list\u001b[38;5;241m.\u001b[39mappend(data_str)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json_file, gemini_model\u001b[38;5;241m.\u001b[39mcount_tokens(data_str))\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToken size of combined video files\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mgemini_model\u001b[49m\u001b[38;5;241m.\u001b[39mcount_tokens(data_list))\n","\u001b[0;31mNameError\u001b[0m: name 'gemini_model' is not defined"],"ename":"NameError","evalue":"name 'gemini_model' is not defined","output_type":"error"}],"execution_count":14},{"cell_type":"markdown","source":"Define methods to upload large data/video files.","metadata":{}},{"cell_type":"code","source":"def upload_to_gemini(path, mime_type=None):\n  \"\"\"Uploads the given file to Gemini.\n\n  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n  \"\"\"\n  file = genai.upload_file(path, mime_type=mime_type)\n  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n  return file\n\ndef wait_for_files_active(files):\n  \"\"\"Waits for the given files to be active.\n\n  Some files uploaded to the Gemini API need to be processed before they can be\n  used as prompt inputs. The status can be seen by querying the file's \"state\"\n  field.\n\n  This implementation uses a simple blocking polling loop. Production code\n  should probably employ a more sophisticated approach.\n  \"\"\"\n  print(\"Waiting for file processing...\")\n  for name in (file.name for file in files):\n    file = genai.get_file(name)\n    while file.state.name == \"PROCESSING\":\n      print(\".\", end=\"\", flush=True)\n      time.sleep(10)\n      file = genai.get_file(name)\n    if file.state.name != \"ACTIVE\":\n      raise Exception(f\"File {file.name} failed to process\")\n  print(\"...all files ready\")\n  print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T19:41:25.305143Z","iopub.execute_input":"2024-12-01T19:41:25.305648Z","iopub.status.idle":"2024-12-01T19:41:25.314095Z","shell.execute_reply.started":"2024-12-01T19:41:25.30561Z","shell.execute_reply":"2024-12-01T19:41:25.312811Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# delete file\ngenai.delete_file(files[0].name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Bibliography\n* https://aistudio.google.com/app/apikey\n* https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf\n* https://ai.google.dev/gemini-api/docs/text-generation?lang=python\n* https://ai.google.dev/api/generate-content#image","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}